?abs
n = 48 # sample size
beta = c(1, 0.5) # true coefficients vector
p = length(beta)
sigma = 0.4 # noise standard deviation
library(mnormt)
set.seed(234865) # set seed
# Generate matrix of covariates
X1 = c(rep(1, n/2), rep(-1, n/2))
X2 = c(rep(2, 6), rep(-2, 6), rep(0, n - 12))
# Verify has the right scaling
crossprod(X1)/n # should be 1
crossprod(X2)/n # should be 1
X = cbind(X1, X2)
# Generate response Y
Y = X %*% beta + sigma * rnorm(n)
# Coordinate descent implementation for the case p = 2
#############################################################
# Helper functions source
source("LassoFunctions.R")
niter = 50 # fixed number of iterations (for simplicity)
lambda = 0 # tuning parameter
beta_start = rep(0, 2) # starting point
# Coordinate descent implementation for the case p = 2
#############################################################
# Helper functions source
source("LassoFunctions.R")
niter = 100 # fixed number of iterations (for simplicity)
# First set of parameters
lambda = 0.0 # tuning parameter 1
beta_start = rep(0, 2) # starting point 1
# First set of parameters
lambda = 0.0 # tuning parameter 1
beta_start = rep(0, 2) # starting point 1
# [ToDo] Create a vector to store objective function values, and calculate the value of f(beta) at the beginning
fvec <- vector(length = niter + 1)
fvec[1] <- lassoobj(X, Y, beta_start, lambda)
for (i in 1:niter){
# [ToDo] Update of beta1
beta1 <- softthresh((1/n) * crossprod(X1, (Y - X2 * beta[, 2])), lambda)
# [ToDo] Update of beta2
beta2 <- softthresh((1/n) * crossprod(X2, (Y - X1 * beta[, 1])), lambda)
# [ToDo] Calculate updated value of f(beta)
fvec[i+1] <- lassoobj(X, Y, beta, lambda)
}
for (i in 1:niter){
# [ToDo] Update of beta1
beta1 <- softthresh((1/n) * crossprod(X1, (Y - X2 * beta[2])), lambda)
# [ToDo] Update of beta2
beta2 <- softthresh((1/n) * crossprod(X2, (Y - X1 * beta[1])), lambda)
# [ToDo] Calculate updated value of f(beta)
fvec[i+1] <- lassoobj(X, Y, beta, lambda)
}
fvec |> tail()
